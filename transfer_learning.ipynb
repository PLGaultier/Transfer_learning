{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "59407ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "# General purpose libraries\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Lambda\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "43d3dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import files from zip folders\n",
    "train_features = pd.read_csv('train_features.csv.zip',compression='zip') #E gap \n",
    "train_labels = pd.read_csv('train_labels.csv.zip',compression='zip')\n",
    "pretrain_features = pd.read_csv('pretrain_features.csv.zip',compression='zip') \n",
    "pretrain_labels = pd.read_csv('pretrain_labels.csv.zip',compression='zip') #only Elumo \n",
    "test_features = pd.read_csv('test_features.csv.zip',compression='zip') #1000 id each one has 1000 features\n",
    "sample = pd.read_csv('sample.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e89296be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only the features\n",
    "train_features = train_features.drop(['Id', 'smiles'], axis=1)\n",
    "train_labels = train_labels.drop('Id', axis=1)\n",
    "pretrain_features = pretrain_features.drop(['Id', 'smiles'], axis=1)\n",
    "pretrain_labels = pretrain_labels.drop('Id', axis=1)\n",
    "test_features = test_features.drop(['Id', 'smiles'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "77fde6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data for evaluating the base model \n",
    "X_pretrain, X_pretest, y_pretrain, y_pretest = train_test_split(pretrain_features, pretrain_labels, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "11dbaa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constant\n",
    "pretrain_input_shape = pretrain_features.shape[1]\n",
    "train_input_shape = train_features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "5c6f3feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtained the pre-trained model with the pretrain_features\n",
    "#Define the model \n",
    "base_model = Sequential()\n",
    "base_model.add(Dense(500, activation='relu', kernel_initializer='he_normal', input_shape=(pretrain_input_shape,)))\n",
    "base_model.add(Dropout(0.3))\n",
    "base_model.add(Dense(200, activation='relu', kernel_initializer='he_normal'))\n",
    "#base_model.add(Dropout(0.3))\n",
    "base_model.add(Dense(100, activation='relu', kernel_initializer='he_normal'))\n",
    "base_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3d517f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_100 (Dense)           (None, 500)               500500    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 500)               0         \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 200)               100200    \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 620,901\n",
      "Trainable params: 620,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "794f28bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "base_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d00db43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/10\n",
      "2657/2657 [==============================] - 10s 4ms/step - loss: 0.0611 - val_loss: 0.0254 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "2657/2657 [==============================] - 8s 3ms/step - loss: 0.0145 - val_loss: 0.0106 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "2657/2657 [==============================] - 8s 3ms/step - loss: 0.0086 - val_loss: 0.0057 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "2657/2657 [==============================] - 8s 3ms/step - loss: 0.0069 - val_loss: 0.0056 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "2657/2657 [==============================] - 8s 3ms/step - loss: 0.0039 - val_loss: 0.0034 - lr: 2.0000e-04\n",
      "Epoch 6/10\n",
      "2657/2657 [==============================] - 9s 3ms/step - loss: 0.0032 - val_loss: 0.0032 - lr: 2.0000e-04\n",
      "Epoch 7/10\n",
      "2657/2657 [==============================] - 8s 3ms/step - loss: 0.0029 - val_loss: 0.0031 - lr: 2.0000e-04\n",
      "Epoch 8/10\n",
      "2657/2657 [==============================] - 8s 3ms/step - loss: 0.0023 - val_loss: 0.0028 - lr: 4.0000e-05\n",
      "Epoch 9/10\n",
      "2657/2657 [==============================] - 8s 3ms/step - loss: 0.0021 - val_loss: 0.0028 - lr: 4.0000e-05\n",
      "Epoch 10/10\n",
      "1758/2657 [==================>...........] - ETA: 2s - loss: 0.0020"
     ]
    }
   ],
   "source": [
    "###### Fit model\n",
    "print(\"Training model...\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.000001)\n",
    "history = base_model.fit(x = pretrain_features, y = pretrain_labels, epochs=10, batch_size = 16, validation_split=0.15,callbacks=[reduce_lr])\n",
    "print(\"Training completed!\")\n",
    "# make predictions\n",
    "yhat = base_model.predict(X_pretest)\n",
    "# evaluate predictions\n",
    "rmse = mean_squared_error(y_pretest, yhat)\n",
    "print('RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304ec95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning curves\n",
    "pyplot.title('Learning Curves')\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.ylabel('RMSE')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb45e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze layers of our base model trained with the pretrain dataset\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffbaed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model for the train dataset\n",
    "#Define the model\n",
    "x_in = Input(shape=train_input_shape)\n",
    "#inlcude our base model here\n",
    "x = base_model(x_in, training=False)\n",
    "x = layers.Dense(100, activation=\"relu\", kernel_initializer='he_normal')(x)\n",
    "#x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(50, activation=\"relu\", kernel_initializer='he_normal')(x)\n",
    "#x = layers.Dense(20, activation=\"relu\", kernel_initializer='he_normal')(x)\n",
    "x = layers.Dense(10, activation=\"relu\", kernel_initializer='he_normal')(x)\n",
    "x_out = Dense(1)(x)\n",
    "# define the model\n",
    "model = Model(inputs=x_in, outputs=x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ec0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model summary \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397f0480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "adam = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=adam, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed43a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "initial_epochs = 10\n",
    "print(\"Training model...\")\n",
    "history = model.fit(x = train_features, y = train_labels, epochs=initial_epochs, batch_size = 2)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d372ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning curves\n",
    "pyplot.title('Learning Curves')\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.ylabel('RMSE')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255e8002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine tuning \n",
    "base_model.trainable = True\n",
    "\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 2\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bbbb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model again for fine tunning\n",
    "tuning_learning_rate = 1e-5\n",
    "adam = tf.keras.optimizers.Adam(tuning_learning_rate)\n",
    "model.compile(optimizer=adam, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c4b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting and fining\n",
    "fine_tune_epochs = 5\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "history_fine = model.fit(x = train_features, y = train_labels, epochs=total_epochs, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796747bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning curves\n",
    "pyplot.title('Learning Curves')\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.ylabel('RMSE')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a67689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model for the train dataset\n",
    "#Define the model\n",
    "x_in = Input(shape=train_input_shape)\n",
    "#inlcude our base model here\n",
    "x = base_model(x_in, training=False)\n",
    "x = layers.Dense(100, activation=\"relu\", kernel_initializer='he_normal')(x)\n",
    "#x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(30, activation=\"relu\", kernel_initializer='he_normal')(x)\n",
    "#x = layers.Dense(20, activation=\"relu\", kernel_initializer='he_normal')(x)\n",
    "x = layers.Dense(10, activation=\"relu\", kernel_initializer='he_normal')(x)\n",
    "x_out = Dense(1)(x)\n",
    "# define the model\n",
    "model = Model(inputs=x_in, outputs=x_out)\n",
    "#Compile the model\n",
    "adam = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=adam, loss='mse')\n",
    "#Fitting and fining\n",
    "fine_tune_epochs = 5\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "history_fine = model.fit(x = train_features, y = train_labels, epochs=total_epochs, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e13e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "y_test = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488d0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac2adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd5998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb00ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['y'] = y_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da23f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2466e585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "6b3a0116",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('prediction_plg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd1e156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
